# Kafka 容量规划

### 其他补充

- 问题一：是否使用 RAID？
- 问题二：存储磁盘的选择？

关于上面两个问题的回答：

##### 问题一：是否使用 RAID？

​		首先谈谈 RAID 的优势：1）提供冗余的磁盘存储空间；2）提供负载均衡，两个对 Kafka 来说都很有吸引力，但是对于 Kafka 来说，已经从「软件」层面实现了这两个机制：

- Kafka 通过 `replica 多副本` 来实现了「冗余机制」，提供了高可靠性；
- Kakfa 通过 `Partition 多分区` 来实现了「负载均衡」，提高 Kafka 的性能；

所以说 RAID 的优势就没有那么明显，不过建议：

- 追求「性价比」可以不搭建 RAID，适用普通磁盘组成存储空间即可

##### 问题二：存储磁盘的选择？

​		首先来说，磁盘对 Kafka 的性能是最重要的，在对 Kafka 集群进行磁盘规划的时候需要面对的选择题就是：选「机械磁盘」还是「固态硬盘 SSD」。

​		对于 Kafka 来说，的确大量使用到磁盘，但 Kafka 从软件层面上实现对磁盘的「[顺序读写操作](https://www.jianshu.com/p/650c9878dee7)」，一定程度上规避极限磁盘最大的「劣势」，即「随机读写操作慢」。从这点来说，SSD 似乎优势并不大，所以建议：

- 不考虑成本，可以使用 SSD；
- 追求性价比，机械硬盘完全能够胜任 Kafka 线上环境；

## 1. 磁盘容量计算和规划

##### 需要考虑的几个元素：

在回答这个问题之前，我们先列出来几个问题：

- 问题1: 业务每天大概多少条消息？
- 问题2: 消息保存几份（每个 Topic 有多少 replica）？
- 问题3: 消息保存多少天（默认两周，可以修改配置）？
- 问题4: 消息是否压缩？

##### 问题：`Kafka 到底需要多大存储空间？`

`提个小需求`：我们现在有业务，每条消息「1 KB」大小，每天大概「 1 亿」条消息， 消息保存「2 份」，并且保存「2 周」，那么我们现在要多少磁盘空间？

​		**一天的数据量**：

```pytho
1 亿 * 1KB * 2 / 1000 / 1000 = 200GB
```

​		但是 Kafka 集群还有其他类型数据，比如：`索引数据` 等，这部分预留「 10 %」磁盘空间：

```pytho
200GB + (200GB * 10% * 2份) = 220GB 
```

​		**保留两周**：

```py
220GB * 14天 ≈ 3TB
```

另外，Kafka 还支持数据压缩（参考：[生产者压缩算法面面观](file:///Users/kevintttccc/Desktop/Kafka%20HTML/11.%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E8%B7%B5%E5%8F%8A%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%EF%BD%9C%E7%94%9F%E4%BA%A7%E8%80%85%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E9%9D%A2%E9%9D%A2%E8%A7%82.html)），假设压缩比是 0.75，那么需要的存储空间就是：

```pyt
3TB * 0.75 = 2.25TB
```

## 2. 带宽容量计算和规划

##### 需要考虑的几个元素：

- 阈值

- 预留 Buffer


案例：如下条件，需要多少台 Kafka 服务器处理业务：

- 千兆网络：1Gbps
- 业务目标 / SLA：「1 小时」处理 1TB 数据

##### 计算方式

​		生产环境，每台实例的带宽阈值为：70%，超过这个值可能存在丢包问题！

```pyth
1）每台实例的带宽阈值
	70%
	
2）单台带宽：
	1Gbps：每秒处理 1Gb 数据
	1Gb * 70% = 700Mb
	
3）单台实例的 Buffer，给 2/3 的资源，最后只能处理的数据量
	700Mb / 3 ≈ 240Mbps	（最终单台能处理的数据量）
	
4）现在来计算多少台机器 1小时内能处理 1TB 数据
	1TB = 1024 * 1024 / 60分 * 60秒  = 277MB/s(每秒)
	
	- 带宽的计算是<Mb>
	277MB * 8byte ≈ 2300Mb/s(每秒)
	
5）单台 240Mb/s，1TB/h = 2300Mb/s
	2300Mb / 240Mb ≈ 10(台)
	
6）如果数据保留两份
	10 * 3 = 30台
```

